
	 # /expengine  =
	 # /expengine/configuration  =
	  mongodb.port  = 27017
	  mongodb.db  =  walter
	  mongodb.host  =  mongo.docker-stack-name.private.xyz
	  mongodb.userlist.db  =  userlist
	  mongodb.userlist.port  = 27017
	  mongodb.userlist.host  =  mongo.docker-stack-name.private.xyz
	  megaups.attribute.url  =  http =//megaups.docker-stack-name.private.xyz/megaups/manageattributes/
	  statsd.prefix  =  com.walter.metrics
	  statsd.port  = 8125
	  statsd.url  =  localhost
	  cacheType  =  concurrentmap
	  kafka.cluster.block.on.buffer.full  = false
	  kafka.cluster.bootstrap.servers  =  kafka.docker-stack-name.private.xyz =9092
	  kafka.cluster.producer.compression.type  =  gzip
	  kafka.cluster.producer.value.serializer  =  org.apache.kafka.common.serialization.StringSerializer
	  kafka.cluster.producer.batch.size  = 16384
	  kafka.cluster.producer.buffer.memory  = 33554432
	  kafka.cluster.consumer.poll.time  = 100
	  kafka.cluster.producer.linger.ms  = 50
	  kafka.cluster.request.timeout.ms  = 250000
	  kafka.cluster.fetch.max.wait.ms  = 500
	  kafka.cluster.producer.key.serializer  =  org.apache.kafka.common.serialization.StringSerializer
	  kafka.cluster.max.poll.records  = 500
	  kafka.cluster.fetch.min.bytes  = 1
	  kafka.cluster.auto.offset.reset  =  latest
	  kafka.cluster.max.partition.fetch.bytes  = 43200
	  cluster.handler.topic  =  walterClusterTopic
	  kafka.cluster.metadata.max.age.ms  = 60000
	  kafka.cluster.session.timeout.ms  = 240000
	  kafka.cluster.consumer.pool.size  = 1
	  kafka.cluster.consumer.commit.option  = 1
	  kafka.cluster.heartbeat.interval.ms  = 3000
	  kafka.cluster.producer.acks  = 0
	  audit.trail.logs.default.limit  = 10
	  aryabhata.url  =  http =//aryabhata.docker-stack-name.private.xyz/aryabhata/
	  kafka.audit.bootstrap.servers  =  kafka.docker-stack-name.private.xyz =9092
	  kafka.audit.producer.value.serializer  =  org.apache.kafka.common.serialization.StringSerializer
	  kafka.audit.producer.key.serializer  =  org.apache.kafka.common.serialization.StringSerializer
	  kafka.audit.producer.batch.size  = 16384
	  kafka.audit.producer.buffer.memory  = 33554432
	  kafka.audit.producer.linger.ms  = 50
	  kafka.audit.producer.acks  =  all
	  audit.trail.topic  =  ee_audit_trails
	  vision.url  =  http =//vision.docker-stack-name.private.xyz/vision/
	  kafka.experiment.action.bootstrap.servers  =  kafka.docker-stack-name.private.xyz =9092
	  kafka.experiment.action.producer.value.serializer  =  org.apache.kafka.common.serialization.StringSerializer
	  kafka.experiment.action.producer.key.serializer  =  org.apache.kafka.common.serialization.StringSerializer
	  kafka.experiment.action.producer.batch.size  = 16384
	  kafka.experiment.action.producer.buffer.memory  = 33554432
	  kafka.experiment.action.producer.linger.ms  = 50
	  kafka.experiment.action.producer.acks  =  all
	  experiment.action.topic  =  walterExperimentActions
	  kafka.trafficsplit.bootstrap.servers  =  kafka.docker-stack-name.private.xyz =9092
	  kafka.trafficsplit.group.id  =  walterConsumerMab
	  trafficSplit.update.kafka.topic  =  mabSplitUpdateTopic
	  kafka.trafficsplit.consumer.commit.option  = 1
	  kafka.trafficsplit.consumer.pool.size  = 1
	  vayu.url  =  http =//vayu.docker-stack-name.private.xyz/vayu/
	  kafka.retry.mech.threadpool.count  =  10
	  kafka.retry.mech.executor.shutdown.await.time.seconds  =  10
	  user.list.executor.shutdown.await.time.seconds  =  10
	  send.metrics.tags.enabled  = false
	  trafficSplit.rme.update.kafka.topic  =  rmeSplitUpdateTopic
    name=walter_prod
