#common properties
    # audit.trail.logs.default.limit = 10
    # user.list.executor.shutdown.await.time.seconds =  10
    # send.metrics.tags.enabled = false
    # statsd.prefix =  com.walter.metrics
    # statsd.port = 8125
    # statsd.url =  10.14.24.174
    # cacheType =  concurrentmap
    # profile = walter_development

#End Points
    # aryabhata.url =  http://localhost:8082/aryabhata/
    # vayu.url =  http://localhost:8081/vayu/
    # vision.url =  http://localhost:8083/vision/
    # megaups.attribute.url =  http://localhost:8084/megaups/manageattributes/

#Database properties
mongodb
	port  :  27017
	db  :  "walter"
	host  :  "localhost"
	userlist
		db  :  "userlist"
		port  :  27017
		host  :  "localhost"

#Kafka Properties
	  # kafka.cluster.block.on.buffer.full = false
    # kafka.cluster.blockOnBufferFull = false
	  # kafka.cluster.bootstrapServers =  localhost:9092
	  # kafka.cluster.producer.CompressionType =  gzip
	  # kafka.cluster.producer.valueSerializer =  org.apache.kafka.common.serialization.StringSerializer
	  # kafka.cluster.producer.batchSize = 16384
	  # kafka.cluster.producer.bufferMemory = 33554432
	  # kafka.cluster.consumer.poll.time = 100
	  # kafka.cluster.producer.lingerMs = 50
	  # kafka.cluster.request.timeout.ms = 250000
	  # kafka.cluster.fetch.max.wait.ms = 500
	  # kafka.cluster.producer.keySerializer =  org.apache.kafka.common.serialization.StringSerializer
	  # kafka.cluster.max.poll.records = 500
	  # kafka.cluster.fetch.min.bytes = 1
	  # kafka.cluster.auto.offset.reset =  latest
	  # kafka.cluster.max.partition.fetch.bytes = 43200
	  # kafka.cluster.handler.topic =  walterClusterTopic
	  # kafka.cluster.metadata.max.age.ms = 60000
	  # kafka.cluster.session.timeout.ms = 240000
	  # kafka.cluster.consumer.pool.size = 1
	  # kafka.cluster.consumer.commit.option = 1
	  # kafka.cluster.heartbeat.interval.ms = 3000
	  # kafka.cluster.producer.acks = 0

	  # kafka.audit.bootstrap.servers =  localhost:9092
	  # kafka.audit.producer.value.serializer =  org.apache.kafka.common.serialization.StringSerializer
	  # kafka.audit.producer.key.serializer =  org.apache.kafka.common.serialization.StringSerializer
	  # kafka.audit.producer.batch.size = 16384
	  # kafka.audit.producer.buffer.memory = 33554432
	  # kafka.audit.producer.linger.ms = 50
	  # kafka.audit.producer.acks =  all
	  # audit.trail.topic =  ee_audit_trails
	  # kafka.experiment.action.bootstrap.servers =  localhost:9092
	  # kafka.experiment.action.producer.value.serializer =  org.apache.kafka.common.serialization.StringSerializer
	  # kafka.experiment.action.producer.key.serializer =  org.apache.kafka.common.serialization.StringSerializer
	  # kafka.experiment.action.producer.batch.size = 16384
	  # kafka.experiment.action.producer.buffer.memory = 33554432
	  # kafka.experiment.action.producer.linger.ms = 50
	  # kafka.experiment.action.producer.acks =  all
	  # experiment.action.topic =  walterExperimentActions
	  # kafka.trafficsplit.bootstrap.servers =  localhost:9092
	  # kafka.trafficsplit.group.id =  walterConsumerMab
	  # trafficSplit.update.kafka.topic =  mabSplitUpdateTopic
	  # kafka.trafficsplit.consumer.commit.option = 1
	  # kafka.trafficsplit.consumer.pool.size = 1
	  # kafka.retry.mech.threadpool.count =  10
	  # kafka.retry.mech.executor.shutdown.await.time.seconds =  10
	  # trafficSplit.rme.update.kafka.topic =  rmeSplitUpdateTopic
